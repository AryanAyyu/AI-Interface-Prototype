// Simulate API calls with delays
const simulateDelay = (ms) => new Promise(resolve => setTimeout(resolve, ms));

export const mockApi = {
  // Get available models
  getModels: async () => {
    await simulateDelay(800);
    return [
      { id: 'gpt-3.5', name: 'GPT-3.5 Turbo', description: 'Fast and cost-effective for most tasks' },
      { id: 'gpt-4', name: 'GPT-4', description: 'More capable than GPT-3.5, better for complex tasks' },
      { id: 'claude-2', name: 'Claude 2', description: 'Excellent for long-form content and dialogue' },
      { id: 'llama-2', name: 'Llama 2', description: 'Open source model good for research and experimentation' }
    ];
  },

  // Get prompt templates
  getTemplates: async () => {
    await simulateDelay(600);
    return [
      { 
        id: 'creative', 
        name: 'Creative Writing', 
        content: 'Write a creative story about a character who discovers a mysterious object that changes their life. Include elements of adventure and personal growth.' 
      },
      { 
        id: 'technical', 
        name: 'Technical Explanation', 
        content: 'Explain the technical concept of [topic] in simple terms. Provide examples and analogies to help a beginner understand.' 
      },
      { 
        id: 'summary', 
        name: 'Text Summary', 
        content: 'Summarize the following text, highlighting the key points and main ideas:\n\n[TEXT]' 
      },
      { 
        id: 'code-help', 
        name: 'Code Assistance', 
        content: 'Help me write a function in [language] that accomplishes the following task: [describe task]. Include comments and error handling.' 
      }
    ];
  },

  // Generate a response from the AI
  generateResponse: async (prompt, parameters, modelId) => {
    await simulateDelay(1500);
    
    // Simulate different responses based on parameters
    const creativity = parameters.temperature > 0.7 ? 'highly creative' : 'straightforward';
    const length = parameters.maxTokens > 800 ? 'detailed' : 'concise';
    
    return `This is a simulated ${creativity}, ${length} response from the ${modelId} model. 

In a real implementation, this would be generated by an AI API using the parameters you selected.

Your prompt was: "${prompt.substring(0, 100)}${prompt.length > 100 ? '...' : ''}"

Parameters used:
- Temperature: ${parameters.temperature}
- Max Tokens: ${parameters.maxTokens}
- Top-P: ${parameters.topP}
- Frequency Penalty: ${parameters.frequencyPenalty}
- Presence Penalty: ${parameters.presencePenalty}

This demonstrates how parameter adjustments affect the AI's output style and content.`;
  }
};

export default mockApi;